---
title: "Chapter 86"
source: "DaVinci Resolve User Manual"
doc_type: "manual"
chapter: 335
---

# Chapter 86

3D Camera Tracking

This chapter presents an overview of using the Camera Tracker node and the

workflow it involves. Camera tracking is used to create a virtual camera in Fusion’s

3D environment based on the movement or a live-action camera in a clip. You can

then use the virtual camera to composite 3D models, text, or 2D images into a

live‑action clip that has a moving camera.

For more information on other types of tracking in Fusion, see Chapter 82, “Using the

Tracker Node,” in the DaVinci Resolve Reference Manual or Chapter 22 in the Fusion

Reference Manual.

Contents

Introduction to Tracking������������������������������������������ 1828

What Is 3D Camera Tracking?������������������������������� 1828

How Camera Tracking Works������������������������������� 1829

The Camera Tracking Workflow�������������������������� 1829

Clips That Don’t Work Well

for Camera Tracking�������������������������������������������������� 1830

Outputting from the Camera Tracker����������������� 1831

2D View����������������������������������������������������������������������������� 1831

3D View���������������������������������������������������������������������������� 1832

Auto-Tracking in the Camera Tracker��������������� 1833

Increasing Auto-Generated Tracking Points�� 1833

Masking Out Objects������������������������������������������������� 1834

Matching the Live-Action Camera��������������������� 1835

Running the Solver���������������������������������������������������� 1836

How Do You Know When to Stop?���������������������� 1837

Using Seed Frames����������������������������������������������������� 1837

Cleaning Up Camera Solves��������������������������������� 1838

Exporting a 3D Scene for Efficiency���������������� 1840

Unalign the 3D Scene Transforms������������������������ 1841

Setting the Ground Plane����������������������������������������� 1841

Setting the Origin��������������������������������������������������������� 1842

Setting the Scale���������������������������������������������������������� 1842

Realign the Scene�������������������������������������������������������� 1842

Viewing the Exported Results������������������������������� 1842


Fusion Fundamentals | Chapter 86 3D Camera Tracking

FUSION

Introduction to Tracking

Tracking is one of the most useful and essential techniques available to a compositor. It can roughly

be defined as the creation of a motion path from analyzing a specific area in a clip over time. Fusion

provides a variety of different tracking nodes that let you analyze different kinds of motion.

Each tracker type has its own chapter in this manual. This chapter covers the tracking techniques with

the Camera Tracker node.

What Is 3D Camera Tracking?

Camera tracking is used for match moving, and it’s a vital link between 2D scenes and 3D scenes,

allowing compositors to integrate 3D CGI elements into live-action clips. The Camera Tracker node

calculates the path of a live-action camera and generates a virtual camera in 3D space. This virtual

camera is intended to be identical to the actual camera that shot the scene, not only in terms of motion

but in matching the lens focal length as well. The calculated position and movement of the virtual

camera is central to realistically compositing 3D elements with live action.

An example of 3D elements integrated in a live-action scene


Fusion Fundamentals | Chapter 86 3D Camera Tracking

FUSION

How Camera Tracking Works

Camera tracking begins by tracking the movement of fixed features from one frame to the next. To put

it another way, camera tracking algorithms follow features that are “nailed to the set.” Objects in the

scene that move independently of the camera movement in the shot, such as cars driving or people

walking, cause poor tracks, so masks can be used to restrict the features that are tracked in order to

improve the results. Additionally, it is helpful to provide specific camera metadata, such as the sensor

size and the focal length of the lens. This information guides the scene reconstruction calculation,

called a solver, toward generating a more accurate virtual camera.

The Camera Tracker’s purpose is to create a 3D animated camera and point cloud of the scene.

A point cloud is a large group of points generated by the solver that roughly recreates the 3D positions

of the tracked features in a scene. The point cloud can then be used as a guide when integrating other

2D or 3D elements alongside live-action features.

The Camera Tracking Workflow

Camera tracking has two main phases:


Tracking, which is the analysis of a scene.


Solving, which calculates the virtual 3D scene.

Once you complete these steps, an animated camera and point cloud are exported from the Inspector

into a 3D composite. The Camera Tracker encompasses this complete workflow within one tool. Five

tabs at the top of the Inspector are roughly laid out in the order in which you’ll use them. These five

tabs are:

Track: Used to track a clip.

Camera: Configures the basic Camera parameters.

Solve: Calculates the 3D placement of the 2D tracking points and reconstructs the camera.

Export: Generates a Camera 3D node, a Point Cloud node, and a 3D scene in the node tree.

Options: Used to customize the look of the onscreen overlays.

The Camera Tracker tab


Fusion Fundamentals | Chapter 86 3D Camera Tracking

FUSION

Clips That Don’t Work Well for Camera Tracking

Even though the Camera Tracker is somewhat automatic, it sometimes needs your help. If you can

identify potential issues before you even track or solve the shot, you can save yourself much time.

Certain types of clips will cause more significant problems for camera tracking than others. Some are

fixable, while for others you just have to admit defeat and figure out another solution. Here is a list of

the types of shots to look out for, as they can be big headaches for camera tracking:

�Lack of depth: Camera tracking requires parallax in a clip in order to work. You must be able to

identify objects further away and objects that are nearer as the camera moves. If everything is at

the same distance from the camera, there is no way to calculate depth. In this case, it’s better to

skip the Camera Tracker node and find another solution.

�Locked-off shots: If the camera does not move, there is no way to calculate which objects are

closer and which are nearer. Again, don’t spend too much time in this situation; it is better to skip

the Camera Tracker node and find another solution.

�Tripod pans: Similar to a locked-off shot, there is no way to calculate which objects are closer and

which are nearer from a pan that remains centered on a locked-off tripod. Skip the Camera Tracker

node and find another solution.

�No detail: Clips like green screens without tracking markers lack enough detail to track. If you are

lucky enough to be involved in the shooting of these types of shots, including tracker markers

makes it much easier to get a good track. Without detail, camera tracking will fail and you will need

to find a more manual solution.

�Motion blur: Fast camera motion or slow shutter speeds can introduce motion blur, which will

make it difficult to find patterns to track. It’s worth trying shots like these to see if there are enough

details to get a good solve, but know when give up and turn to another solution.

�Rolling shutter: CMOS-based cameras sometimes introduce distortion due to the shutter

capturing different lines at slightly different times. This distortion can create significant problems

for camera tracking. Sometimes it is possible to create motion vectors with the Optical Flow node

to create new in-between frames without the wobble distortion of the rolling shutter. Then you can

use the corrected image to connect to the Camera Tracker.

�Parallax issues: When objects at different distances in a shot overlap in the frame, the overlapping

area can be misinterpreted as a corner. Having a tracker assigned to an overlapping angle like this

will cause errors as the parallax starts to shift and the overlapping area slides. This can be solved

in Fusion by removing that tracker before running the solver.

�Moving objects: It’s difficult to capture a shot where objects in the clip do not move. People, cars,

animals, or other object may move in and out of a shot. These objects move independent of the

camera movement and must be eliminated or they will cause solving errors. You can fix these

issues by masking out objects that are not “nailed to the set.” The masks are then connected to

the Track Mask input on the Camera Tracker node.

TIP: Some shots that cannot be tracked using Fusion’s Camera Tracker can be performed in

dedicated 3D camera-tracking software like 3D Equalizer and PF Track. Camera tracking data

from these applications can then be imported in the Camera3D node in Fusion.


Fusion Fundamentals | Chapter 86 3D Camera Tracking

FUSION

Outputting from the Camera Tracker

Unlike most Fusion nodes, the Camera Tracker node has two outputs:

�The primary output is a 2D view used when you are setting up the Track, refining the camera, and

performing your initial solve.

�There is also a 3D output used after your initial solve for viewing the camera path and point cloud

in 3D space. This view can be helpful when you are refining tracks to increase the accuracy of

the solve and aligning your ground plane. It can be used simultaneously with the 2D output in

side-by-side views.

Note that the selection of tracks in the 2D view and their corresponding locators (in the point cloud) in

the 3D view are synchronized. There are also viewer menus available in both the 2D and 3D views to

give quick control of the functionality of this tool.

2D View

The 2D view is the primary display for the node. Viewing the node displays the image being tracked

as well as overlay tracker markers and their motion paths. A dedicated toolbar gives you access to the

common features used to track and solve a clip.

The Camera Tracker 2D output with toolbar and auto-track points


Fusion Fundamentals | Chapter 86 3D Camera Tracking

FUSION