---
title: "INSANE New Ai Features in DaVinci Resolve 20"
video_id: IsDYGfh6K9E
channel: MrAlexTech
url: https://youtube.com/watch?v=IsDYGfh6K9E
duration_seconds: 2064.0
date_processed: 2025-11-03
---

## Transcript
What up folks, today we're going to be taking a look at all of the new AI features within DaVinci Resolve Studio 20. Yes, I said studio, all of these are only available within the paid studio version, but we're going to whip through them all as quickly as we can, I'll give you a brief overview and show you roughly how they work. Now, everything you're seeing in this video is being run on this 3XS system by scan.co.uk, which is being powered by the latest Nvidia RTX 5070 Ti. Thank you to Scan and Nvidia for sponsoring this very video. Nvidia have gone big on AI processing with our new 50 series of RTX GPUs, and this 5070 Ti is no exception, making short work of all of these new AI intensive tasks within DaVinci Resolve Studio 20. To check out Scan's line of Nvidia RTX 50 series GPUs, simply click on the link down in the description below. Right, let's jump straight in to talk about one of the features which people have wanted for quite some time in DaVinci Resolve, the AI Music Editor. This allows you to lengthen or shorten songs on your timeline, and then the AI will take over, make cuts where it needs to be, to make them sound like nothing had ever changed. It's really good, I've really been enjoying this one, and this one is dead easy, so we've got a music track on the timeline, all we need to do, give it a click, open up the inspector, scroll down until you see the AI Music Editor, then there's two ways you can do this, you can simply hit adjust and it'll think about it, and then you can come in and put the target length within here, let's say four minutes. But the way I prefer to do it is simply tick this live trim, then you can simply grab your music, make it shorter or longer on your timeline, it will then analyze the clip, figuring out where it needs to make the cuts to make this work, and then it'll do the rest for you. So you can see these little zigzaggy lines on our music, that's where it's made our cuts, and if we play this back, it's seamless. We can then make this longer, if we've changed our mind, we want it to be a little bit longer, like so. Generally, you get a few different versions, so once again, make sure it's selected in the inspector, in the music editor, you can see versions, you might get one, two, three, or four. I've got four in this instance, so I can see the different versions, it's made different cuts at different points, so we can just see which version we prefer. If we're done, we're happy with it, but we may want to make some kind of minor amendments to it on the timeline, untick this live trim, that allows you to then adjust the length without it recalculating, and if you want to kind of really set it in stone, you can right click, come to decompose in place using clips only, and that'll give you the actual sort of tracks back rather than this AI music edited version. The next one, not dissimilar, AI beat detector. Does exactly what it says on the tin, we'll pick out the beats in a track for you, making it easier to edit to the beat, if that's what you want to do. So once again, edit page, we've got a music track on our timeline, we simply right click, right at the bottom, show music beats, give that a click, it'll analyze the clip, it's really quick this one, and then you get these little markers just showing you where the edit points are. Then if we grab a piece of media on the timeline, we can snap to those beats. This is the snapping icon here, so if it's not snapping, it's because that's turned off, just give this little magnet a click, and it will work. Now just a quick heads up, you can actually do this for multiple clips at once, just highlight them all, right click, show music beats, and it will go through all three of the clips doing the exact same thing. Now sticking once again with audio stuff, they've introduced a new AI audio assistant. Now this one is really clever, I think they could improve this in certain ways, I really like what it's doing, essentially it's trying to do a full mix for you. It will separate your music, it will create tracks, it will do your dialogue sort of leveling, EQing, applying different effects to try and give you a finished sort of result for whatever purpose, YouTube for example. But the problem with it is that it doesn't always tell you what it's doing, so it can do some strange things, and it's an absolute nightmare to undo them or find out what it's doing. So we've got this timeline here, it's kind of a mini vlog that I filmed, we've got some just general footage with nothing much going on, me talking to the camera, we've got some B-roll, I've put some music down here, I haven't labelled any of the tracks, I haven't done any real work to this timeline. We've also brought in some ambient sounds, some sound effects, some general sound design and all this sort of stuff. Now it's highly recommended before you run this one, duplicate your timeline, just in case it does something weird, so I'm going to find my timeline within the media pool, come down to duplicate timeline, so then we've got this backup. Then we simply click on timeline at the top, AI tools, and then audio assistant. We've got delivery standards, so we want YouTube, that will settle the different levels and whatever else, and then we click auto mix. And it's going to do a few things, audio classification, dialogue mix, music mix, sound effects and ambience and final mastering, and you can actually see it doing it on the timeline, which is pretty cool. Give that a minute to finish what it's doing, and then we'll get a final result. And here it is. So it's suggested a bunch of the audio, it's figured out what's the sound effects and what's music, it's colour coded them, and it's put them on the right tracks. If we go to the dialogue, for example, that's applied some AI voice isolation, we've got the dialogue leveler on there, we've probably got some other stuff, the de-esser, let's open up the mixer, it's probably really done some dynamics for us. It's done a bunch of work to make this work. And if we hit play, we're going to go called Solihull. And it's only a small town, there's nothing too exciting, really, we've got a bit of a shopping centre, got a couple of pubs. It's not done a bad job. But here's an example of it doing something just a little bit strange. Right at the end, things we need to do. So let's get back to it. It phased the audio, but there's no phase on the timeline. If we jump over to fairlight, we can't see anything on here. It's not until you open up the bus and then change this to the audio assistant, the levels, and you can see it's done a bunch of keyframes, which you'd then have to come along and get rid of. So while I really like this one, I think it's a really neat addition. I think it will save some people time. I think it maybe goes a little bit too far. I'd like some more control over it, some tick boxes to say do these things, but not these things. And maybe give us a list at the end to say these are the things that I've done. So if you do want to take some things off, you kind of have a rough idea of where to look. I do think the AI in Resolve 20 is really good. It takes away lots of the boring tasks, but leaves us to do the fun creative stuff. This is the only one which I feel maybe goes a bit too far and does too much of the process, which again is why I'd like to be able to customize it a bit and take it back just a smidge and leave us to do some of the bits while it does some of the boring bits like labels, tracks, and color codes things and does all the classification. Next up, let's take a look at another one that people have wanted for quite some time, animated subtitles. So technically this isn't kind of a new AI feature. The AI subtitles have been there for a while, but now you can do animated subtitles. So let me show you those. Once again, dead easy. So I've got this clip on my timeline of me just talking to the camera. I'm going to click on timeline, the very top AI tools, and we're going to create subtitles from audio. There's a few options. You can download some additional languages if your language isn't in the default list. I'm going to leave it as auto because mine's English, so it's nice and easy. We can then change some of the settings like characters per line, how many lines and all that sort of stuff. We'll create that that won't take long at all. And now we've got our subtitles. Now if we jump into the effects library, come down to titles. First of all, you can grab any of these standard titles, even the ones that aren't animated, drag them over here to the subtitle track, and it will style all of the subtitles in that style, which is pretty cool. It's better than it used to be where you didn't have a huge amount of control. If you're either scroll down or within the titles area, you should see subtitles. There's some specific subtitles here, and once again, we can drag them on and they're just different styles. And a little bit further down, we've got animated, we've got lollipop, rotate, slide in statement and word highlight. So if I grab word highlight, drop that on there. As I hit play, you can see it's jumping from word to word. We can customize this by clicking on the subtitles track, jumping into track, and you can see we can do right on words, we can show speakers, we can change the colors, change the highlight of fill, enable outlines, all this sort of stuff. You can also create your own subtitles. It's a bit tricky. I need to dig into it a little bit more, but the functionality is there. So eventually people will make some nice animated subtitles for the DaVinci Resolve 20, hopefully. If you're smart, have a go at that and let us know. Now, before we jump into the next, something that's really key about these AI features within DaVinci Resolve 20 is that they are all local. Everything runs locally on your machine, which is quite different to how AI works in a lot of other software. That means that you can run all of these even without an internet connection, which is great. So if you're on a flight, for example, you can still create your subtitles, you can still do all the things that you need to do. It means you don't need to worry about confidentiality, because nothing is being sent up to the cloud and analyzed in order to produce these, it's all being run locally again on your device. The one thing you do need to bear in mind though, is that that means the performance of these AI tools will vary from machine to machine. Now any modern system will be able to run them. It's just how fast they run them will depend on the performance of your system. So once again, thanks to Scan and Nvidia for sponsoring this video lending me this PC with this RTX 5070 Ti, so that I can run this demo nice and quickly. Right next up, we've got two features which technically existed before and they've been good for a while, but they've just been updated and now they're better than ever. Magic masks and depth maps. So let's kick things off with magic masks. We're on the color page, we click on this icon to enable our magic mask panel, that's down here. I'm going to change the quality to better, we will enable our overlay and then all we need to do is click on our subject. So it's now clicking rather than squiggly lines. So I'm going to click on her face and her face gets picked up, we'll click on our body and her body gets picked up, and then we can hit this icon to track. I'll leave this going in real time so you can see it for yourself and it's doing a really, really good job. It's a little bit slower than the previous version was, but in my use case so far it's been much more accurate. So you can see it's done a really, really good job of this lady running here. We can turn the overlay off and then any color grading we do will only be affecting the person within the track or the thing it will work on objects to. We can invert it to select everything else or we can come into the effects library, grab something like a mosaic blur and we can apply that on there instead. Magic masks, they were always good before now they feel even better. I've made a full video talking all about magic masks which you can check out somewhere. Go give that a watch if you want to see more examples and more detail of how to use it. Oh and it's important to note these new and improved magic masks are only available on the color page at the moment. The fusion version is still the old magic masks. Hopefully they bring this new magic mask to the fusion page at some point soon. Right next up depth maps. So if you've never seen depth maps they look something like this. So we've got this guy here walking towards this tractor. We've got white, we've got gray and we've got black. So everything that's white is within our selection. Everything that's gray sort of fades out of our selection and anything that's black isn't within our selection. So as things get closer to the screen like this tractor here you will see they will get brighter which means they are being more affected by the things that we do on the color page. Now in this version they just seem more accurate. Look it's picking up all of the individual sort of cables. If we turn that off we can see kind of these hoses, all of the arms of this tractor. It's pretty detailed but everything is being picked up quite nicely. Now to show you how to actually apply that you need a node on the color page. You search within the effects library for the depth map. You grab the depth map, you shove it on your node and that's about it. You can change the quality from faster and better. We can toggle on the preview, you can invert it if we want to. We can change the map adjustment so we can bring the far limit in basically excluding more things from our selection. We can change the near limit including more things within our selection. We've got gamma, we've got isolate specific depth. So if you're looking to pick up something within the frame rather than foreground versus background you can tweak that and you can finesse the mask. Now if I turn the preview off and let's just do something wild with this you can see everything within the foreground is being affected by our color grade, our change and then it slowly fades out and as things get closer to us to our point they get more and more affected by this wild grade but it's also really good for effects. A common one, defocus background so I'm going to search for that, drop that on there, connect our blue to our blue. This gives us a nice sort of out of focus bokeh effect. I'll need to jump back to my depth map and just adjust my near limit a little bit and there we go. Obviously that's a bit strong but you can see what's happening. It's slowly going out of focus. We've got this nice sort of transition between our sharp bits and our blurry background but our guy in the middle is staying within focus so is our tractor and if we can toggle that on and off you can see the difference. Next up we've got smooth cut. Again smooth cut is in transition which has been in DaVinci Resolve for ages, years and years. They've just improved it by adding speed warp. Now here's a cool example just to show you exactly what it's doing. To find it you open up the effects library. I'm on the portrait view so everything looks weird. My effects library is over here. We go to the video transitions, smooth cut is within there. We drag that. We put it on our timeline. Let's zoom in a bit. If we give that a click, open up the inspector. There's this new speed warp tick box. Without that we just get the old sort of merging of everything together and with speed warp enabled it will try and use AI to fill in the gaps. Now this is a cool example because remember none of these frames exist but if we hit play it's taking his face looking like this, looking like this. We can mess with the different modes. We can give it some easing. It generally works better a little bit shorter and it's filling in. It's adding all those frames to give us a really nice transition between these two still images. Now as a practical use case it allows you to hide cuts between different takes. This is two different takes of me and what we can do is just bring these down. Let's try and find a nice point. There we go. Then grab a smooth cut, plunk that on there. We've got this speed warp on. Let's give it a bit of easing and then if we hit play it's trying to hide that cut. Sometimes you need to tweak it and find the perfect frame. There you go. That's pretty damn good and you can barely see the cuts between those two different takes. I really like these. I think they're really clever. Once again they are heavy so how quick they run will depend on your system but they're a neat addition. Now another one which again has been there for a long time but has just been improved is Super Scale. Here we're actually working on an 8k timeline. We've got some 1080p footage. We've got this footage on the timeline. It doesn't look bad to be honest but we can use Super Scale to give it a boost. We give the footage a click, scroll right to the bottom of the inspector. We have AI Super Scale. Take that. We've got a bunch of options. The new options I believe are 3x and 4x so we could go to 4x and that's giving it a boost. We can change the sharpness and the noise reduction. We can go 4x enhanced which as you can see is doing quite a big difference. We're going from a little bit soft to much sharper. Again mess with the sharpness and the noise reduction as required and if you're on Nvidia RTX cards you also get this Nvidia RTX video version which runs a bit quicker because it's using some in-built upscaling features of these new RTX cards. Right next up let's talk about something completely new. It's the AI voice convert. This is the actual audio that you're listening to right now. This is from the in-built mic on the camera which is a fair distance away so it won't sound very good. I'm using AI now to replace my voice with an AI voice model I created. Now with this one it's super important to know what this is and what this isn't. It's not text-to-speech you can't feed it a script and it will say things for you and it's not for replacing generally other people's words or dialogue with your own because it doesn't work particularly well for that. What it's designed for is creating the voice model of some good dialogue of someone like I have of myself and then if I've recorded myself that the audio is dodgy or I need to fill in some gaps or I need to do something with it I can then replace it with my own voice. So here we are on the edit page and I've got that clip I just recorded. What I can do is simply right click the audio on the timeline there's a new option for voice convert. We get this little pop-up I can choose the track. Door 1 so basically overwrites render in place or put it on a new track so let's do a new track. We can change the file name and then we can choose the voice model. So this comes with four included two female us and two male so if we went to male one us and then simply click render it's going to analyze that clip and then change the voice and now we've got this. A little dialogue with your own because it doesn't work particularly well for that. What it's designed for is creating the voice model of some good dialogue of someone which sounds okay it sounds a little bit robotic now as mentioned I have created one of my own so if I right click once again voice convert I have an alex we can then render and now we've got this. You can't feed it a script then it will say things for you and it's not for replacing generally other people's words or dialogue with your own because and it has a slightly robotic sort of twinge to it but overall it's not too bad. Now as mentioned earlier it's not really designed for replacing other people and it especially doesn't like different accents. Here's some other dialogue for someone else. Just a restricted ground with insufficient space for maneuvering and if we try and convert this one to sound more like me, endanguously restricted ground with insufficient space for maneuvering. The substantial victory achieved was due to the skill of his officers. It sounds like me but with a weird accent so it kind of still takes the accent it's not trying to completely erase what was there before with the new voice it will take a lot of the attributes of the original so I personally think it's a really clever implementation even if that does somewhat limit its uses. So to actually make your voice model in the media pool I've got this nice long clip it's from a podcast recording of me talking within my studio you want an example like this of good high quality audio. If we right click come down to AI tools there is a DaVinci AI voice training you get this pop up give it a read you must have legal rights to use any voice recordings and then accept. It will ask you to download the additional voice model training because that's not included it's a free download it's about four gig so that might pop up once that's done I'll give this a name Alex2 we can change the training accuracy and then we hit start. Now this is a slow one again depending on your system it's going to take some time you get this little processing window for a while as it sort of processes the clip and you'll end up with this little voice convert model status thing in the bottom right hand corner and you can still work in resolve while it's doing the rest of that conversion so you can still edit it might be a bit choppy but you can do what you need to do and then once it's done you'll have a new option within the voice convert list and that's it so I think this is actually a smart implementation as mentioned I know some people want like a text to speech text to voice sort of model I think Blackmagic are trying to be sensible with this so you can't just rip people off and and do strange things with it so yeah we'll see again let me know your thoughts on this new voice convert down in the comments below next up AI multicam switcher I think this one's really smart and it works pretty well actually it will do exactly what it says on the tin and try and automatically figure out when to cut your angles if you've got a multicam now it's not just looking at the waveforms it also uses the AI to look at the faces to look at the mouth to try and figure out who's talking and you can include wide angles and all that sort of stuff so I've already got my multicam on my timeline here what we need to do let's get rid of the inspector let's open up the dual viewer mode which is this icon here and hopefully you should see your multicam stuff on the left if not double click on your clip on the timeline then make sure to click on this little drop down and come to multicam and here's our multicam angles so I've got one of me one of cases and one of me and cases now this is the new little button this is the AI multicam smart switch give that a click and then we get a bunch of options the minimum edit duration whether you want a faster or slower cut we can edit the change delay we can automatically detect wide angles and choose the frequency that they appear let's go low for this example use a wide angle for intros and outros use wide angles for silences and the smart switch setup so we want it to run faster or better and if we want to not look at the faces we can change it to use audio only where then it would just look at the waveform I'm going to leave it as faster but with the video then we're going to click analyze and it's just going to whip through this whole podcast now this podcast is about an hour just under 55 minutes ish I think it is and I'm running at 370 ish fps so it's going to cut this whole thing for us in about four minutes so I can just chill have a coffee and wait for that to chop our podcast for us so five minutes later we've got a bunch of cuts and here's a nice wide angle and then it cuts to me as I'm talking and then it cuts back to the wide and then Casey for a little bit and then the two of us me again and overall it does a pretty good job it's a pretty neat feature if you do a load of multicams it's definitely worth checking out in tele script so we're going to finish off with a bunch of these new audio kind of AI features that have added some are more useful than others we're going to kick things off with in tele script now on paper this is a common thing it's a popular thing online you feed a script to the AI you give it your footage and then it kind of gives you a rough cut Black Magic have tried to implement that within DaVinci Resolve just doesn't seem to give me particularly consistent results hopefully it gets better because as mentioned I do think this is something that people want and it is a cool idea it yeah let me show you so we've got this super simple script nothing much and we've recorded this over three separate clips there's a couple of mistakes there's a couple of retakes but it's nothing too fancy so if we select all three of these clips right click come down to AI tools and then we've got create new timeline using in tele script we then point it to that script it will transcribe all of those clips to figure out obviously the spoken word and what's being said and all that sort of stuff and then it will try and give us a rough cut based on that script but straight away you can see we've got 25 seconds and nothing for some reason so let's get rid of that and then if we just hit play what's going on folks it's Alex here and welcome to Mr today we're talking about AI is life so let's jump on the PC but there's loads of new features within resolve 20 we've got things like so in some areas it's done an okay job and others it's just cut too early so I'd have to come in and just extend these a bit and mess with these edit points so it's it's almost there it just seems to be cutting things too early and doing some slightly strange things these additional shots here these are my retakes so this has worked this has done what you expect it to do so this line here I said twice it's given me the other take so I can review it back so this is the one it's put on the main timeline so let's jump on the PC and get cracking shall we and then this is the one it figured was incorrect which is true this one was a mess up so let's jump on the PC and get tracking I said tracking by mistake so there you go so that has worked it's just kind of the edit point it is meant to be a rough cut but it feels even a little bit rough for a rough cut has potential needs tidying up again maybe we just need a bit more control to be able to say you know leave a bigger gap I'd prefer to have too much of a gap between the edit points than not enough because that's easier to fix in my view rather than having to push everything along and tweak it and this that and the other just maybe need some improvements here and there next up AI checkerboard not something I found myself needing all that much but I can see why it would be useful for certain people in certain situations situations like this me and Casey recorded a podcast two separate mics but it's all come through on one track which means I can't apply any adjustments to Casey versus me independently because it's all stuck together if we jump over to Fairlight make sure we give the audio track a click then we can right click come down to AI tools checkerboard to new tracks it's going to transcribe that audio figure out the speakers however many there are in our case it's just two and then split all the spoken word into two separate tracks so I've got speaker one and speaker two now I could rename these if I wanted to I guess this top one personal stuff is Casey and this bottom track here is me so I could rename them and then I could apply any EQ or any audio effects independently on either myself or Casey's next up we have the AI ADR cues so this automatically transcribes your clips to give you a script for if you need to record any additional dialogue so Fairlight once again for this one we've got this track here and we simply right click once again come to AI tools there is a create ADR cues and then create ADR cues with speakers if you've got multiple speakers we'll click create ADR cues it's just going to transcribe it and then it's going to look like nothing's happened if we open up the ADR panel which is this one up here you can see we've got these little sections so these are timed these are just the spoken word and we've got a bit of a script here so if we wanted to come in and replace some of this dialogue we now have a script to do so now I've just done some ADR using that clip which brings me nicely onto the next feature which is the AI dialogue matcher if you've recorded some audio in different rooms you've got different room tones different reverb echo all that sort of stuff you can use this dialogue matcher to make your clean audio sound like it was recorded somewhere else now this won't fix bad audio it kind of works the other way it's best if you're trying to make like a studio mic like this sound like it was recorded outside or in a different room or in my case a dirty horrible stairwell so we've got the original footage here so we're just going to run down these stairs and then the ADR recorded with this microphone we'll use this as a reference and see if we can and obviously it sounds completely different now you can do this on Fairlight or you can now do it on the edit page as well so I'm going to click this clip here with our original audio then we're going to go to clip at the very top come down to AI tools we've got dialogue matcher and we need to capture the dialogue profile of this clip once that's done you select on your other audio we want to apply it to make sure that's highlighted on the timeline go to clip once again AI tools dialogue matcher and then we're going to apply the dialogue profile and that's going to apply an effect to this one to make it sound more like the other so we're just going to run down these stairs we'll use this as a reference and see if we can ADR it to make it sound somewhat similar and it's maybe gone a little bit heavy with the reverb but you get the idea it's added this reverb to make it sound like I was recording in this stairwell if we go back up to clip we can go AI tools dialogue matcher we can untick to disable it and we can also remove the applied profile if we need to on fairlight it's very similar you find the clip to steal the profile from right click AI tools dialogue matcher capture the dialogue profile go to the one you wish to apply it to right click AI tools dialogue matcher and then you apply the dialogue very similarly to that one we also have an EQ matcher and a level matcher so EQ will try and make one microphone sound like a different microphone so if you've recorded out on about on a lav mic and then a studio mic you can steal the EQ from one and try and match it up to another and leveler will just level out the volume the levels to make it sound a similar level so again really quickly you can do this on fairlight and you can do it on the edit page we're going to steal the EQ once again from our original clip so we highlight it on the timeline we click on clip we come down to audio operations this time and we've got an EQ matcher and a level matcher if we go EQ matcher we capture the EQ profile we click on our other clip we want to apply it to once again clip audio operations EQ matcher apply to clip EQ straight away in the equalizer we can see what it's done let's try to match the EQ of our original clip so we're just going to run down these stairs we'll use this as a reference and see if we can ADR it to make it sound somewhat similar now obviously that was quite an extreme example with all of that reverb and it didn't really do the best job it did okay it was enough for the demonstration that I wanted to show you but in a slightly more realistic example of going from an unprotected room on a lav mic into my studio which does have soundproofing and then jumping over to a studio mic like this you can make it do a much better job making this lav mic sound much more like this studio mic than it originally did now also you can apply all of this to the voice clones so I've made a voice clone here I've captured the EQ of the original footage so we can come to this track go to clip audio operations EQ matcher apply to clip EQ and now we've got the EQ of our voice clone should sound more like our original audio words or dialogue with your own because it doesn't work particularly well for that anyway next up remove silences kind of does what it says on the tin but also kind of doesn't let's take a look so we're on Fairlight once again we've got this clip here it's me talking and you can see there's a bunch of silences so what you need to do click on the track itself so it's highlighted and then you mark arrange so I'm going to come to the end and just hit oh on my keyboard to mark these in and out points and then if I right click I've got the option to remove silence and then I get this remove silence all the red areas are due to be removed I can change the threshold which is in db's so what exactly is silent the prehead the point running up to the silence the post the minimum to strip and then we can fade it if we want to so we can tweak these and we can see exactly what it's doing and then if we hit remove silence it's removed all of those silences but it's only removed it from the audio and not the video so as I say kind of does what you expect but also not it could be useful if you're wishing to just tidy up your audio and you want it to be silent where it's silent maybe there's some room tone or whatever but if you're actually looking to shorten your clip down and get rid of all the silences so you've got kind of a rough cut this won't do it instead you need to use the old fashioned not that old fashioned you need to use the previous transcription model so this time around the edit page I've got that same clip we're going to right click ai tools audio transcription and then transcribe this isn't new in 20 this is the same as it was in resolve 19.5 I think it was once that's done you'll get your transcriptions these little markers here the brackets with the three dots these are your silences if we click on these three little dots in the top right hand corner we've got the option to remove silent portions which will get rid of all of those then if we do a control a to select everything and then this icon here will insert to the timeline or append and then we can close that and that's dropped all of the clips on the timeline with the silences with the cuts taken out but that can also be a bit hit and miss it can sometimes cut things a bit early or leave silences what I'd love to see is that remove silences box where you get to tweak things from the fairlight page this new one on that transcriptions so then we could just tweak exactly what we wanted to remove tweak that little bit and then add all the individual clips to the timeline that would be perfecto right rather long video but I hope you enjoyed this one talking about all the ai tools with intervention resolve studio 20 let me know all of your thoughts and feelings down in the comments below thank you ever so much for watching take it easy I'll see you next time
